{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work\n",
    "1. 請比較使用不同層數以及不同 Dropout rate 對訓練的效果\n",
    "2. 將 optimizer 改成使用 Adam 並加上適當的 dropout rate 檢視結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "import itertools\n",
    "# Disable GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 資料前處理\n",
    "def preproc_x(x, flatten=True):\n",
    "    x = x / 255.\n",
    "    if flatten:\n",
    "        x = x.reshape((len(x), -1))\n",
    "    return x\n",
    "\n",
    "def preproc_y(y, num_classes=10):\n",
    "    if y.shape[-1] == 1:\n",
    "        y = keras.utils.to_categorical(y, num_classes)\n",
    "    return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "\n",
    "# Preproc the inputs\n",
    "x_train = preproc_x(x_train)\n",
    "x_test = preproc_x(x_test)\n",
    "\n",
    "# Preprc the outputs\n",
    "y_train = preproc_y(y_train)\n",
    "y_test = preproc_y(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128], drp_ratio=0.2):\n",
    "    \"\"\"Code Here\n",
    "    建立你的神經網路\n",
    "    \"\"\"\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    \n",
    "    for i, n_units in enumerate(num_neurons):\n",
    "        if i == 0:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1))(input_layer)\n",
    "            x = keras.layers.Dropout(drp_ratio)(x)\n",
    "        else:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1))(x)\n",
    "            x = keras.layers.Dropout(drp_ratio)(x)\n",
    "    \n",
    "    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Code Here\n",
    "設定超參數\n",
    "\"\"\"\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 2.0961 - accuracy: 0.2291 - val_loss: 1.8975 - val_accuracy: 0.3307\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.9106 - accuracy: 0.3120 - val_loss: 1.7903 - val_accuracy: 0.3685\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.8322 - accuracy: 0.3423 - val_loss: 1.7213 - val_accuracy: 0.3947\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.7711 - accuracy: 0.3661 - val_loss: 1.6713 - val_accuracy: 0.4122\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.7314 - accuracy: 0.3829 - val_loss: 1.6361 - val_accuracy: 0.4231\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.6952 - accuracy: 0.3939 - val_loss: 1.6008 - val_accuracy: 0.4378\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.6620 - accuracy: 0.4085 - val_loss: 1.5720 - val_accuracy: 0.4478\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.6332 - accuracy: 0.4188 - val_loss: 1.5504 - val_accuracy: 0.4547\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.6133 - accuracy: 0.4271 - val_loss: 1.5272 - val_accuracy: 0.4630\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.5903 - accuracy: 0.4362 - val_loss: 1.5168 - val_accuracy: 0.4622\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.5672 - accuracy: 0.4441 - val_loss: 1.4972 - val_accuracy: 0.4706\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.5515 - accuracy: 0.4472 - val_loss: 1.4822 - val_accuracy: 0.4803\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.5317 - accuracy: 0.4573 - val_loss: 1.4697 - val_accuracy: 0.4783\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.5133 - accuracy: 0.4625 - val_loss: 1.4604 - val_accuracy: 0.4887\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.5003 - accuracy: 0.4680 - val_loss: 1.4349 - val_accuracy: 0.4948\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.4891 - accuracy: 0.4716 - val_loss: 1.4339 - val_accuracy: 0.4906\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.4768 - accuracy: 0.4748 - val_loss: 1.4365 - val_accuracy: 0.4922\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.4564 - accuracy: 0.4838 - val_loss: 1.4150 - val_accuracy: 0.5017\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.4440 - accuracy: 0.4877 - val_loss: 1.4182 - val_accuracy: 0.4892\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.4336 - accuracy: 0.4909 - val_loss: 1.3942 - val_accuracy: 0.4998\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.4213 - accuracy: 0.4957 - val_loss: 1.3831 - val_accuracy: 0.5088\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.4117 - accuracy: 0.4986 - val_loss: 1.3886 - val_accuracy: 0.5018\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.4072 - accuracy: 0.5022 - val_loss: 1.3738 - val_accuracy: 0.5070\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.3932 - accuracy: 0.5066 - val_loss: 1.3718 - val_accuracy: 0.5119\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.3798 - accuracy: 0.5095 - val_loss: 1.3791 - val_accuracy: 0.5060\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.3665 - accuracy: 0.5131 - val_loss: 1.3699 - val_accuracy: 0.5128\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.3623 - accuracy: 0.5161 - val_loss: 1.3668 - val_accuracy: 0.5109\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 1.3538 - accuracy: 0.5175 - val_loss: 1.3457 - val_accuracy: 0.5181\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.3432 - accuracy: 0.5215 - val_loss: 1.3487 - val_accuracy: 0.5209\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.3284 - accuracy: 0.5292 - val_loss: 1.3477 - val_accuracy: 0.5223\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.3264 - accuracy: 0.5275 - val_loss: 1.3439 - val_accuracy: 0.5207\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 1.3150 - accuracy: 0.5334 - val_loss: 1.3268 - val_accuracy: 0.5253\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.3025 - accuracy: 0.5345 - val_loss: 1.3317 - val_accuracy: 0.5207\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.2935 - accuracy: 0.5390 - val_loss: 1.3246 - val_accuracy: 0.5266\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.2864 - accuracy: 0.5429 - val_loss: 1.3320 - val_accuracy: 0.5251\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.2773 - accuracy: 0.5464 - val_loss: 1.3179 - val_accuracy: 0.5304\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.2718 - accuracy: 0.5473 - val_loss: 1.3143 - val_accuracy: 0.5337\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.2636 - accuracy: 0.5498 - val_loss: 1.3088 - val_accuracy: 0.5357\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.2529 - accuracy: 0.5543 - val_loss: 1.3052 - val_accuracy: 0.5284\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.2429 - accuracy: 0.5602 - val_loss: 1.3144 - val_accuracy: 0.5298\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.2407 - accuracy: 0.5596 - val_loss: 1.3081 - val_accuracy: 0.5326\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.2299 - accuracy: 0.5633 - val_loss: 1.3043 - val_accuracy: 0.5357\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.2236 - accuracy: 0.5647 - val_loss: 1.2954 - val_accuracy: 0.5340\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.2155 - accuracy: 0.5681 - val_loss: 1.3089 - val_accuracy: 0.5319\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.2087 - accuracy: 0.5699 - val_loss: 1.2866 - val_accuracy: 0.5443\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.1997 - accuracy: 0.5748 - val_loss: 1.2947 - val_accuracy: 0.5317\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.1939 - accuracy: 0.5740 - val_loss: 1.2972 - val_accuracy: 0.5366\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.1923 - accuracy: 0.5767 - val_loss: 1.2791 - val_accuracy: 0.5409\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.1776 - accuracy: 0.5801 - val_loss: 1.2930 - val_accuracy: 0.5422\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.1735 - accuracy: 0.5837 - val_loss: 1.2833 - val_accuracy: 0.5444\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.1687 - accuracy: 0.5851 - val_loss: 1.2842 - val_accuracy: 0.5465\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.1616 - accuracy: 0.5862 - val_loss: 1.2803 - val_accuracy: 0.5466\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.1494 - accuracy: 0.5914 - val_loss: 1.2725 - val_accuracy: 0.5480\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.1383 - accuracy: 0.5932 - val_loss: 1.2792 - val_accuracy: 0.5457\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.1331 - accuracy: 0.6000 - val_loss: 1.2717 - val_accuracy: 0.5458\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.1309 - accuracy: 0.5991 - val_loss: 1.2753 - val_accuracy: 0.5499\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.1272 - accuracy: 0.5998 - val_loss: 1.2866 - val_accuracy: 0.5397\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.1198 - accuracy: 0.5997 - val_loss: 1.2690 - val_accuracy: 0.5459\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.1129 - accuracy: 0.6038 - val_loss: 1.2673 - val_accuracy: 0.5472\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.1049 - accuracy: 0.6076 - val_loss: 1.2758 - val_accuracy: 0.5458\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.0970 - accuracy: 0.6079 - val_loss: 1.2684 - val_accuracy: 0.5468\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.0880 - accuracy: 0.6107 - val_loss: 1.2701 - val_accuracy: 0.5466\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.0902 - accuracy: 0.6116 - val_loss: 1.2844 - val_accuracy: 0.5445\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.0817 - accuracy: 0.6130 - val_loss: 1.2689 - val_accuracy: 0.5490\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.0738 - accuracy: 0.6181 - val_loss: 1.2638 - val_accuracy: 0.5472\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.0665 - accuracy: 0.6203 - val_loss: 1.2744 - val_accuracy: 0.5528\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.0635 - accuracy: 0.6194 - val_loss: 1.2681 - val_accuracy: 0.5517\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.0615 - accuracy: 0.6201 - val_loss: 1.2635 - val_accuracy: 0.5538\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.0536 - accuracy: 0.6240 - val_loss: 1.2658 - val_accuracy: 0.5532\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.0448 - accuracy: 0.6263 - val_loss: 1.2628 - val_accuracy: 0.5556\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.0360 - accuracy: 0.6299 - val_loss: 1.2727 - val_accuracy: 0.5510\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.0320 - accuracy: 0.6301 - val_loss: 1.2625 - val_accuracy: 0.5564\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.0320 - accuracy: 0.6327 - val_loss: 1.2564 - val_accuracy: 0.5564\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.0238 - accuracy: 0.6343 - val_loss: 1.2641 - val_accuracy: 0.5507\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.0160 - accuracy: 0.6357 - val_loss: 1.2661 - val_accuracy: 0.5523\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.0119 - accuracy: 0.6366 - val_loss: 1.2709 - val_accuracy: 0.5531\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 1.0067 - accuracy: 0.6398 - val_loss: 1.2634 - val_accuracy: 0.5544\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.9995 - accuracy: 0.6409 - val_loss: 1.2637 - val_accuracy: 0.5543\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.9908 - accuracy: 0.6456 - val_loss: 1.2571 - val_accuracy: 0.5536\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.9908 - accuracy: 0.6449 - val_loss: 1.2689 - val_accuracy: 0.5559\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.9848 - accuracy: 0.6477 - val_loss: 1.2698 - val_accuracy: 0.5568\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.9731 - accuracy: 0.6521 - val_loss: 1.2640 - val_accuracy: 0.5623\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.9735 - accuracy: 0.6508 - val_loss: 1.2669 - val_accuracy: 0.5544\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.9623 - accuracy: 0.6569 - val_loss: 1.2770 - val_accuracy: 0.5530\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.9711 - accuracy: 0.6533 - val_loss: 1.2903 - val_accuracy: 0.5532\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.9702 - accuracy: 0.6528 - val_loss: 1.2659 - val_accuracy: 0.5561\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.9529 - accuracy: 0.6600 - val_loss: 1.2738 - val_accuracy: 0.5567\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.9466 - accuracy: 0.6611 - val_loss: 1.2796 - val_accuracy: 0.5570\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.9424 - accuracy: 0.6622 - val_loss: 1.2612 - val_accuracy: 0.5622\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.9434 - accuracy: 0.6642 - val_loss: 1.2750 - val_accuracy: 0.5576\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.9346 - accuracy: 0.6663 - val_loss: 1.2537 - val_accuracy: 0.5621\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.9250 - accuracy: 0.6684 - val_loss: 1.2583 - val_accuracy: 0.5603\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.9271 - accuracy: 0.6687 - val_loss: 1.2700 - val_accuracy: 0.5578\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.9311 - accuracy: 0.6671 - val_loss: 1.2687 - val_accuracy: 0.5580\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.9163 - accuracy: 0.6724 - val_loss: 1.2784 - val_accuracy: 0.5576\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.9141 - accuracy: 0.6731 - val_loss: 1.2826 - val_accuracy: 0.5586\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.9021 - accuracy: 0.6768 - val_loss: 1.2738 - val_accuracy: 0.5579\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.9021 - accuracy: 0.6765 - val_loss: 1.2605 - val_accuracy: 0.5630\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.8956 - accuracy: 0.6799 - val_loss: 1.2761 - val_accuracy: 0.5570\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.8969 - accuracy: 0.6787 - val_loss: 1.2809 - val_accuracy: 0.5584\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\"\"\"Code Here\n",
    "撰寫你的訓練流程並將結果用 dictionary 紀錄\n",
    "\"\"\"\n",
    "keras.backend.clear_session() # 把舊的 Graph 清掉\n",
    "\n",
    "model = build_mlp(input_shape=x_train.shape[1:])\n",
    "model.summary()\n",
    "optimizer = keras.optimizers.Adam(lr=LEARNING_RATE)\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
    "\n",
    "model.fit(x_train, y_train, \n",
    "          epochs=EPOCHS, \n",
    "          batch_size=BATCH_SIZE, \n",
    "          validation_data=(x_test, y_test), \n",
    "          shuffle=True)\n",
    "\n",
    "# Collect results\n",
    "train_loss = model.history.history[\"loss\"]\n",
    "valid_loss = model.history.history[\"val_loss\"]\n",
    "train_acc = model.history.history[\"accuracy\"]\n",
    "valid_acc = model.history.history[\"val_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\"\"\"Code Here\n",
    "將結果繪出\n",
    "\"\"\"\n",
    "plt.plot(range(len(train_loss)), train_loss, label=\"train loss\")\n",
    "plt.plot(range(len(valid_loss)), valid_loss, label=\"valid loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(len(train_acc)), train_acc, label=\"train accuracy\")\n",
    "plt.plot(range(len(valid_acc)), valid_acc, label=\"valid accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}